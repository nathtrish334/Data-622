---
title: 'Data 622 Homework #2'
author: "Trishita Nath"
date: "4/3/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Homework #2
Based on the latest topics presented, bring a loan_data of your choice and create a Decision Tree where you can solve a classification or regression problem and predict the outcome of a particular feature or detail of the data used.

Switch variables to generate 2 decision trees and compare the results. Create a random forest for regression and analyze the results.

Based on real cases where desicion trees went wrong, and 'the bad & ugly' aspects of decision trees (https://decizone.com/blog/the-good-the-bad-the-ugly-of-using-decision-trees), how can you change this perception when using the decision tree you created to solve a real problem?

Format: document with screen captures & analysis.

## Data Exploration

I will the loan_data on loan approval status that I uploaded on GitHub.


```{r, message = FALSE, warning = FALSE, echo=FALSE}
# loading libraries
library(ggplot2)
library(tidyverse)
library(tidymodels)
library(kableExtra)
library(rpart.plot)
library(ggcorrplot)
library(caret)
library(cvms)
library(tidyr)
library(dplyr)
library(VIM)
library(corrplot)
library(purrr)
library(scales)
library(Hmisc)
library(naniar)
library(rattle)
library(psych)
library(mice)
library(randomForest)
library(caTools)
library(class)
library(rpart)

```

### Loading Data

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Reading the loan_data
loan_data <- read.csv('https://raw.githubusercontent.com/nathtrish334/Data-622/main/Assignments/Assignment_02/loan_approval.csv', stringsAsFactors = FALSE)

#Dimensions of the loan_data
dim(loan_data)

head(loan_data)%>% kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% 
  scroll_box(width="100%",height="300px")
```

For this loan_data, the target variable for my analysis is the `Loan_Status`

## Data Processing

### Missing Values

Below is te summary of the missing values per feature

```{r, message=FALSE, warning=FALSE, echo=FALSE}
## Counts of missing data per feature
dataset_missing_counts <- data.frame(apply(loan_data, 2, function(x) length(which(is.na(x)))))
dataset_missing_pct <- data.frame(apply(loan_data, 2,function(x) {sum(is.na(x)) / length(x) * 100}))

dataset_missing_counts <- cbind(Feature = rownames(dataset_missing_counts), dataset_missing_counts, dataset_missing_pct)
colnames(dataset_missing_counts) <- c('Feature','NA_Count','NA_Percentage')
rownames(dataset_missing_counts) <- NULL

ggplot(dataset_missing_counts, aes(x = NA_Count, y = reorder(Feature, NA_Count))) + 
  geom_bar(stat = 'identity', fill = 'steelblue') +
  geom_label(aes(label = NA_Count)) +
  labs(title = 'Missing Counts') +
  theme(plot.title = element_text(hjust = 0.5), axis.title.y = element_blank(), axis.title.x = element_blank())

#  A plot of missing value patterns using nanair package
gg_miss_upset(loan_data)
```

### Imputing Data

I will remove the `Loan_ID` variable, convert categorical variables into factors then impute the loan_data using the mice package following Random Forest method.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
# Remove 'Loan_ID' then convert variables into factors
loan_data <- loan_data %>%
  select(-'Loan_ID') %>%
  mutate(
    Gender = as.factor(Gender),
    Married = as.factor(Married),
    Dependents = as.factor(Dependents),
    Education = as.factor(Education),
    Self_Employed = as.factor(Self_Employed),
    Credit_History = as.factor(Credit_History),
    Property_Area = as.factor(Property_Area),
    Loan_Status = as.factor(Loan_Status)
  )

#imputate by using the random forest method
init <- mice(loan_data, maxit = 0)
predM <- init$predictorMatrix
set.seed(123)
imputed <- mice(loan_data, method = 'rf', predictorMatrix = predM, m=5)

loan_data <- complete(imputed)
#summary(loan_data)
summary(loan_data)%>% kable() %>% kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>% scroll_box(width="100%",height="400px")

```

## Model Building

### Decision Tree

#### Data Splitting

I will split the data into training and testing datasets in the ratio 80:20

```{r, message=FALSE, warning=FALSE, echo=FALSE}
sample = sample.split(loan_data$Loan_Status, SplitRatio = 0.8)
train = subset(loan_data, sample == TRUE)
test = subset(loan_data, sample == FALSE)


train_factored <- train %>%
  
  mutate(
    Gender = as.factor(Gender),
    Married = as.factor(Married),
    Dependents = as.factor(Dependents),
    Education = as.factor(Education),
    Self_Employed = as.factor(Self_Employed),
    Credit_History = as.factor(Credit_History),
    Property_Area = as.factor(Property_Area),
    Loan_Status = as.factor(Loan_Status))

test_factored <- test %>%
  
  mutate(
    Gender = as.factor(Gender),
    Married = as.factor(Married),
    Dependents = as.factor(Dependents),
    Education = as.factor(Education),
    Self_Employed = as.factor(Self_Employed),
    Credit_History = as.factor(Credit_History),
    Property_Area = as.factor(Property_Area),
    Loan_Status = as.factor(Loan_Status))


d_tree <- rpart(Loan_Status ~ ., 
               data=train_factored, method="class")
rpart.plot(d_tree, nn=TRUE)

summary((d_tree))
```

Credit history seems to be an important predictor for loan approval.

I will now apply the decision tree to the test data and create a confusion table to evaluate the accuracy of the classifications.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
pred_tree = predict(d_tree,test_factored)# predicting the class labels
pred_tree
# Confusion Tree
confusionMatrix(predict(d_tree,type="class"), train_factored$Loan_Status)
```

The model is 81.5% accurate.

#### Regression Model

```{r, message=FALSE, warning=FALSE, echo=FALSE}
train.loan_labels <- train[,12]
test.loan_labels <- test[,12]

reg_fit <- rpart(Loan_Status ~ ., 
               data=train_factored, method="anova")
rpart.plot(reg_fit, nn=TRUE)

```

### Random Forest

Random Forest reduces overfitting problem in decision trees and also reduces the variance and therefore improves the accuracy.

```{r, message=FALSE, warning=FALSE, echo=FALSE}
r_forest <- randomForest::randomForest(Loan_Status ~ ., data = train_factored, method="class")
r_forest

# Predicted random forest
forest_pred <- predict(r_forest, test_factored)
forest_pred
```

## Conclusion

In my opinion, decision tree offers better performance when analyzing a feature of a loan_data. Random Forest is good to avoid low quality of data but might build a tree that will not take into consideration the significance that the“Feature” has in the final decision.